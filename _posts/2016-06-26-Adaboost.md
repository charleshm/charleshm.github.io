---
published: true
author: Charles
layout: post
title:  "Adaboost模型"
date:   2016-06-26 8:30
categories: 机器学习
---

Boosting这其实思想相当的简单，大概是，对一份数据，建立M个模型（比如分类），一般这种模型比较简单，称为弱分类器(weak learner)。每次分类都将上一次分错的数据权重提高一点再进行分类，越往后执行，训练出的模型就越会在意那些容易分错（权重高）的点。这样最终得到的分类器在测试数据与训练数据上都可以得到比较好的成绩。

![][1]

Boosting可以用下面的公式来表示：

![][2]

训练集中一共有$n$个点，我们可以为里面的每一个点赋上一个权重$W_i$，表示这个点的重要程度，通过依次训练模型的过程，我们对点的权重进行修正，如果分类正确了，权重降低，如果分类错了，则权重提高，初始的时候，权重都是一样的。上图中绿色的线就是表示依次训练模型，可以想象得到，程序越往后执行，训练出的模型就越会在意那些容易分错（权重高）的点。当全部的程序执行完后，会得到M个模型，分别对应上图的$y_1(x)…y_M(x)$，通过加权或投票的方式组合成一个最终的模型$Y_M(x)$。

我觉得Boosting更像是一个人学习的过程，开始学一样东西的时候，会去做一些习题，但是常常连一些简单的题目都会弄错，但是越到后面，简单的题目已经难不倒他了，就会去做更复杂的题目，等到他做了很多的题目后，不管是难题还是简单的题都可以解决掉了。


[1]:http://7xjbdi.com1.z0.glb.clouddn.com/weak_learner.png
[2]:http://7xjbdi.com1.z0.glb.clouddn.com/Boosting_1.png
